{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Motivation\nBeing in the course last year I noticed that there was some avoidable frustration when using some of the libraries.\n\nML is fun, you don't need a lot to get started, I think these should be more than plenty.\nAlso, numpy, sklearn, keras, pytorch, pandas etc, are some of the best documented libraries out there.\nRemember to ask questions in the forums if something doesn't work, many have likely the same problem and are grateful for someone to have the curage and ask about it.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# ðŸ”¨ Survival Toolkit","metadata":{}},{"cell_type":"markdown","source":"### ðŸ¼  Pandas\nWe're going to use the Titanic dataset, if you run this notebook on Kaggle, it's already imported, otherwise change below as in the comments","metadata":{}},{"cell_type":"code","source":"# import pandas and give it a shorter name \nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing CSV data\nYou can import many other files such as parquet read_parquet, or read_json, read_excel and they all work analogously\nin the course you'll mostly use csv\nYou can download the csv file here https://www.kaggle.com/rahulsah06/titanic?select=train.csv if you don't want to sign up for kaggle :-(","metadata":{}},{"cell_type":"code","source":"#if you have data on your local machine or elsewhere change the path\npath = '../input/titanic/train.csv'\n#df is short for dataframe\ndf = pd.read_csv(path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ok, lets see what we have here\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#you can print the top n rows with\nn = 3\ndf.head(n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#similarilty the bottom n\ndf.tail(n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#or take a random sample size n\ndf.sample(n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I didn't pass any arguments to read_csv()\nIt actually has a lot of useful arguments.\nOne is useful to know, as it that led to one of the frustrating errors I mentioned earlier.\n\n**index_col**\n\nif you don't pass an argument pandas will just enumerate the rows\nbut sometimes! you do have an index column, it makes no sense to use it as data, \nit's not a rank and just a random enumeration\n","metadata":{}},{"cell_type":"code","source":"#lets have a look again\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Notice somthing about PassengerId?\nindeed, it's an index column, so we either drop it, or we can use it directly by speciying it by int or string (name of col)","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(path, index_col = 0)\n#this is equivalent\n#df = pd.read_csv(path, index_col = 'PassengerId')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#and if you want the enumerated index back\ndf.reset_index(inplace = True) \n#without inplace it just gives you a view without manipulating the df\n#this is actually true for a lot of functions in pandas","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#like drop\n#you can drop rows axis=0, or columns axis=1, many or just one like this\ndf.drop('PassengerId', axis=1).head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make it permanent\ndf.drop('PassengerId', axis=1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loc and iLoc","metadata":{}},{"cell_type":"code","source":"#there are many different ways to access a subset of rows and columns, most straightforward are loc and iloc\n#iloc you can think of more numpy esque and loc as just using names\ndf = pd.read_csv(path)\ndf.loc[2, \"Survived\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[2, [\"Survived\", \"Name\", \"Sex\"]]\n#this btw outputs a pandas series, sometimes you'll run into bugs\n#you can fix by wrapping 2 in a list [2] and you'll get a dataframe, try it","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[[2, 4, 6], [\"Survived\", \"Name\", \"Sex\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with iloc\ndf.iloc[[2, 4, 6], [0, 2, 3]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hmm that does not seem right, why?\n#fix it\ndf.iloc[[?, ?, ?], [0, 2, 3]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the question marks reminded me of a cool jupyter feature\n? df.iloc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"if you ever want to know what a function does or read the docs about it just do ? foo","metadata":{}},{"cell_type":"code","source":"df.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Masking","metadata":{}},{"cell_type":"code","source":"#you can define a boolean mask\nmask = df.Survived == 1\nmask = df['Survived'] == 1\n#these are equivalent","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets only look at survivors\ndf[mask]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#you can create more elaborate masks\nmask2 = df.Name.str.contains('Adele')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[mask2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#chain them with & (and) or | (or) \ndf[mask & mask2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#you also don't have to save them in a variable\ndf[(df.Survived == 1)].head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Apply","metadata":{}},{"cell_type":"code","source":"#you can apply functions to rows and columns\n#0 apply along rows (i.e. over all rows)\n#1 apply along columns (i.e. from left to right over all columns)\ndf[['Fare']].apply('mean', axis=0) #pandas has string shortcuts for all stat functions sum, median, mean, etc.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#you can write your own function and use it the same way\ndef foo(x):\n    return \"I love ML\"\n\ndf.apply(foo, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#useful stats\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.median()\n#etc.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One Hot and label encoding directly in pandas\nfor the course projects you get just use pd.get_dummies or pd.factorize if you want to do one-hot encoding because you have access to the full dataset\nin reality or in kaggle competitions you'll want to use sklearns label encoder or one_hot_encoder etc. because not all categories might be in future data.\nAn additional warning, redundancy is poison, if we convert Sex to one_hot you'll get two columns Male and Female, however in most cases if Male == 1, Female == 0 is implied. \nThis can lead to overfitting and make your matrix non-invertible. It likely won't matter to pass tests but if you want that extra 0.005 on the Leaderboard, well label encoder (factorize) etc are better suited, if you like https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features read up :-).","metadata":{}},{"cell_type":"code","source":"#one hot\npd.get_dummies(df.Sex).head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoding, index = df.Sex.factorize()\ndf[\"F/M\"] = encoding\ndf[[\"F/M\", \"Sex\"]].head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### saving csv files\nThis seemed to cause quite some errors and frustration in the projects\nremember how we took care of index? \nwell you can also take care of the header and that's not only when reading but saving\nsince the projects expect a csv file with a given format, make sure you don't add things like a header or the index that pandas automatically added when reading in.","metadata":{}},{"cell_type":"code","source":"#it would be pretty straightforward to do:\ndf.to_csv('Submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#but look what happens\npd.read_csv(\"Submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pandas saved the added index column as Unnamed: 0\n#if you try to submit this you'll get an error (in kaggle too btw)\n#instead do \ndf.to_csv(\"Submission.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tada\npd.read_csv(\"Submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sometimes you may also not want a header, i.e. if the submission expects ONLY the results\ndf.to_csv(\"Submission.csv\", index = False, header = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"Submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numpy","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#making Sex a numeric feature\ndf[\"Sex\"] = df[\"Sex\"].apply(lambda x: 1 if x == \"female\" else -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#you can convert pandas dataframes or series directly to numpy\nA = df[[\"Pclass\", \"Survived\", \"Sex\"]].to_numpy()\ny = df[\"Fare\"].to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Transpose of A\nA.T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Matrix multiplication in pyton via @\nA.T @ A","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ralf would cringe:\nx = np.linalg.inv(A.T @ A) @ (A.T @ y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is the easiest way to save your predictions, then just do to_csv()\ndf[\"Predictions\"] = A @ x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[[\"Fare\", \"Predictions\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"subtle differences between lists and arrays","metadata":{}},{"cell_type":"code","source":"alist = [1,2,3]\nanarray = np.array(alist)\n\nprint(alist + alist)\nprint(anarray + anarray)\nprint(alist * 2)\nprint(anarray * 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Matrices","metadata":{}},{"cell_type":"code","source":"n_rows = 3\nn_cols = 5\nzeros = [0.0]*5\nZ = np.zeros((n_rows, n_cols))\nA = np.array([zeros, zeros, zeros])\nB = np.zeros_like(A)\nO = np.ones_like(A)\nfor m in [Z, A, B, O]:\n    print(f\"A Matrix \\n {m} \\n \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Z","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"A","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"B","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"O","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reshape array to one column\nA.reshape((-1, 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make a 3d Matrix out of it\nA.reshape((1, 3, 5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#transpose\nA.reshape((n_cols, n_rows))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change to one dimension\nA.flatten()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#3x3 Identity Matrix\nnp.eye(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#3x3 Random Matrix\nR = np.random.random((3,3))\nR","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"R.max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get range of ints from start to end -1 \nnp.arange(1, 10, step = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make arange matrix\nnp.arange(1,16).reshape((3,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create #\"num\" equally spaced items from start to stup\nnp.linspace(start = 5, stop = 10, num = 6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.linspace(start = 5, stop = 10, num = 11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#padding\nnp.pad(O, pad_width = 1, mode='constant', constant_values=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dot products\nnp.array([1,2,3]) @ np.array([4,5,6])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array([1,2,3]).dot(np.array([4,5,6])) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sums, mean, median, min, max, std, var\nO.sum()  #switch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#argmax might come in handy too for multiclass classification\nR.argmax(axis=1) # returns the index with the highest value per row (axis=1 => evaluate over columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#squeeze you may use this a lot #get rid of the extra dimension that's useless\nM = np.random.randint(0, 100, (1, 5, 2, 3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"M.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"S = np.squeeze(M)\nS.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#similarily\nE = np.expand_dims(S, axis=0) #axis tells numpy where you want to insert the extra dimension\nE.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array_equal(E, M)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's it\nthere are lots more useful functions for numpy and pandas, but I don't think you'll need to know much more to get started","metadata":{}},{"cell_type":"markdown","source":"### Sklearn helpful guide\nthis is a a great place to get started https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n\nBe sure to read the docs carefully and for simple tasks like regression, it may be worth to try the numpy theoretical approaches if you run into weird bugs","metadata":{}}]}